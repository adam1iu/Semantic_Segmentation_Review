## what

* 它是一种表示学习方法，消除了要求人类标记数据的先决条件。
*  自监督学习系统提取并使用自然可用的相关上下文和嵌入的元数据作为监督信号。
*  自我监督研究“通过上下文预测的无监督视觉表示学习”通过使用空间上下文作为用于训练丰富视觉表示的监督信号来预测图像的一个矩形部分相对于另一个的位置定位。 例如，猫的右耳相对于猫的眼睛位于右上方位置。 这种方法允许在没有事先明确的语义标记的情况下学习猫，狗或公共汽车。

### Self-Supervised Reinforcement Learning

* 狗训练师可以奖励狗的积极行为并惩罚消极行为。 随着时间的推移，狗会找出并学习获得奖励所采取的行动。 

* 类似地，在强化学习中，导航机器人学习如何在课程中导航以及在与环境中的某些事物发生碰撞时受到惩罚。 在这两种情况下，这种奖励和惩罚反馈强化了要执行的操作和要避免的操作。强化学习在奖励反馈系统的存在下运作良好。 它还需要一套全面的培训数据，在考虑成功，时间和成功之前所需的迭代次数时可能不切实际。

* 在没有基于奖励的反馈系统的情况下，狗或导航机器人可以通过好奇地探索环境来自学。 来自BAIR²的研究人员创造了一种“内在的好奇心模型”，这是一种自我监督的强化学习系统，即使在没有明确的反馈的情况下也可以工作。 它利用好奇心作为一种自然的奖励信号，使代理人能够探索其环境并学习在其生命后期使用的技能。 参见：自我监督预测的好奇心驱动探索和随附的文章。

* 使用自我监督的学习机器可以通过自然进化和其行为的后果进行预测，类似于新生儿如何通过观察和存在和好奇来学习生命的最初几周/几个月中的大量信息。 自我监督学习有可能将学习规模扩大到新用例所需的水平，包括但不限于医学，自动驾驶，机器人，语言理解和图像识别中的用例。

* 通过使用运动分割技术从场景的运动场和相机运动之间的几何约束确定相对深度，自我监督学习已经成功地在没有人类监督的情况下估计相对场景深度。

* In medicine, it has found use cases [robotic surgery](https://arxiv.org/abs/1705.08260) and in [dense depth estimation in monocular endoscopy](https://arxiv.org/abs/1806.09521).

  

## where 

### 动机

* 监督学习需要大量的标签数据；
* 人可以决定“黄色”单词语义意义从上下文，如：出现在 “t-shirt,” “fridge,” “county,” or “mobile.” 等信息。
* 机器学习方法Word2vec预测单词的语义上下文基于周围的单词。

### Self-supervised vs. supervised learning

* 自我监督学习是有监督的学习，因为它的目标是从输入对和标记输出中学习一个映射。 
* 不需要在自我监督学习中明确使用标记的输入 - 输出对。 相反，输入中可用的相关性，嵌入式元数据或领域知识被隐含地和自主地从数据中提取并用作监督信号。 

### Self-supervised vs. unsupervised learning

* 自我监督学习就像无监督学习一样，因为系统在不使用明确提供的标签的情况下学习。 
* 它与无监督学习不同，因为我们没有学习数据的固有结构。 
* 与无监督学习不同，自我监督学习不是以聚类和分组，降维，推荐引擎，密度估计或异常检测为中心。

### Self-Supervised vs. semi-supervised learning

* 标记和未标记数据的组合用于训练半监督学习算法，其中较少量的标记数据与大量未标记数据相结合可以加速学习任务。 
* 自我监督学习是不同的，因为系统完全学习而不使用明确提供的标签。



## why

### Q: Why is self-supervised learning relevant

* 由于许多原因，自我监督学习至关重要，但主要是因为监督学习的方法和可扩展性都存在缺陷。
* 监督学习是一个艰巨的过程，需要收集大量数据，清理它，手动标记，训练和完善为您正在解决的分类或回归用例而构建的模型，然后使用它来预测标签 未知数据。 例如，对于图像，我们收集大型图像数据集，手动标记图像中的对象，学习网络，然后将其用于特定用例。 这种方式与人类学习方法截然不同。
* 人类学习是基于试验的，永久的，多源的，并且可以同时执行多项任务。 我们主要以无人监督的方式学习，使用实验和好奇心。 我们也以受监督的方式学习，但我们可以从更少的样本中学习，并且我们非常好地推广。
* 对于有监督的学习，我们花了数年时间收集并专业地注释数以千万计的标记边界框或多边形和图像级别注释，但这些数据集Open Images，PASCAL Visual Object Classes，Image Net和Microsoft COCO相比数十亿 每天在社交媒体上生成的图像，或在自动驾驶中需要对象检测或深度感知的数百万视频。 常识知识存在类似的可伸缩性论点。



